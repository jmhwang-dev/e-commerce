# SparkApplication: Spark Operator가 관리하는 Spark 작업 정의서
apiVersion: sparkoperator.k8s.io/v1beta2  # Spark Operator API 버전
kind: SparkApplication  # Spark 작업을 정의하는 쿠버네티스 커스텀 리소스
metadata:
  name: sample-job  # 작업 이름
  namespace: spark
spec:
  type: Scala          # 애플리케이션 언어 (Scala, Python, Java, R 지원)
  mode: cluster        # 실행 모드 (cluster: 운영용, client: 개발/테스트용)
  image: ghcr.io/YOUR_USERNAME/spark-custom:latest  # 사용할 Spark Docker 이미지
  imagePullSecrets:    # private 이미지 pull을 위한 인증 정보
    - ghcr-secret
  # 실행할 메인 클래스 (Scala/Java의 경우)
  mainClass: org.apache.spark.examples.SparkPi
  # 실행할 JAR 파일 경로 (local://는 이미지 내부 경로를 의미)
  mainApplicationFile: local:///opt/spark/examples/jars/spark-examples_2.12-3.4.0.jar
  sparkVersion: 3.4.0  # 사용할 Spark 버전
  restartPolicy:       # 실패 시 재시작 정책
    type: Never        # Never(재시작 안함), Always(항상 재시작), OnFailure(실패시만)
  
  # Driver 설정 (Spark 작업을 조정하고 관리하는 메인 프로세스)
  driver:
    cores: 1           # Driver가 사용할 CPU 코어 수
    coreLimit: 1200m   # 최대 CPU 사용량 (1.2 코어)
    memory: 512m       # Driver 메모리 크기
    serviceAccount: spark-driver  # 사용할 ServiceAccount
  
  # Executor 설정 (실제 데이터 처리를 수행하는 워커 프로세스들)
  executor:
    cores: 1           # 각 Executor가 사용할 CPU 코어 수
    instances: 2       # 실행할 Executor 개수 (병렬 처리 수준)
    memory: 512m       # 각 Executor의 메모리 크기
---
