# K8s Data Platform

Kubernetes ê¸°ë°˜ ë°ì´í„° í”Œë«í¼ìœ¼ë¡œ MinIO(Object Storage)ì™€ Sparkë¥¼ í™œìš©í•œ ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚â”€â”€â”€â–¶â”‚     MinIO       â”‚â”€â”€â”€â–¶â”‚  Spark Jobs     â”‚
â”‚                 â”‚    â”‚ (Object Storage)â”‚    â”‚ (Data Pipeline) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ êµ¬ì„± ìš”ì†Œ

- **MinIO**: S3 í˜¸í™˜ ê°ì²´ ìŠ¤í† ë¦¬ì§€ (ë°ì´í„° ë ˆì´í¬)
- **Spark**: ë¶„ì‚° ë°ì´í„° ì²˜ë¦¬ ì—”ì§„
- **Spark Operator**: Kubernetesì—ì„œ Spark ì‘ì—… ê´€ë¦¬

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ë°°í¬
```bash
cp ../.env.example ../.env # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
chmod +x scripts/deploy_all.sh
./scripts/deploy_all.sh
```

### 2. MinIO ì›¹ ì½˜ì†” ì ‘ì†
- URL: http://localhost:30901
- ê³„ì •: `.env` íŒŒì¼ì— ì„¤ì •í•œ ê´€ë¦¬ì ê³„ì •

### 3. ìƒ˜í”Œ Spark ì‘ì—… ì‹¤í–‰
```bash
kubectl apply -f spark-jobs/sample-job.yaml
```

### 4. ì‘ì—… ìƒíƒœ í™•ì¸
```bash
kubectl get sparkapplications -n spark
```

## ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
infra/k8s/
â”œâ”€â”€ minio/              # MinIO ì„¤ì •
â”‚   â”œâ”€â”€ namespace.yaml  # MinIO ì „ìš© ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì •ì˜
â”‚   â”œâ”€â”€ pv.yaml         # ì˜êµ¬ ì €ì¥ì†Œ ë³¼ë¥¨ ì •ì˜
â”‚   â”œâ”€â”€ pvc.yaml        # ì €ì¥ì†Œ ìš”ì²­ ì •ì˜
â”‚   â””â”€â”€ values.yaml     # MinIO Helm Chart ì„¤ì •ê°’
â”œâ”€â”€ spark/              # Spark Operator ì„¤ì •
â”‚   â”œâ”€â”€ namespace.yaml  # Spark ì „ìš© ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì •ì˜
â”‚   â”œâ”€â”€ rbac.yaml       # ê¶Œí•œ ì„¤ì • (ServiceAccount, Role, ClusterRole ë“±)
â”‚   â””â”€â”€ values.yaml     # Spark Operator Helm Chart ì„¤ì •ê°’
â”œâ”€â”€ spark-jobs/         # Spark ì‘ì—… ì •ì˜
â”‚   â”œâ”€â”€ sample-job.yaml # ê¸°ë³¸ ì˜ˆì œ ì‘ì—… (SparkPi ê³„ì‚°)
â”‚   â”œâ”€â”€ etl-job.yaml    # ETL íŒŒì´í”„ë¼ì¸ ì‘ì—…
â”‚   â””â”€â”€ olist-analysis.yaml # ì´ì»¤ë¨¸ìŠ¤ ë°ì´í„° ë¶„ì„ ì‘ì—…
â”œâ”€â”€ scripts/            # ë°°í¬/ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ deploy.sh       # ì „ì²´ í”Œë«í¼ ìë™ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ cleanup.sh      # ì „ì²´ í”Œë«í¼ ì •ë¦¬(ì‚­ì œ) ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ README.md          # ì´ ë¬¸ì„œ
```

## ğŸ” GitHub Container Registry ì‚¬ìš©

ë³¸ì¸ì˜ ì»¤ìŠ¤í…€ Spark ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´:

1. **spark-jobs/*.yaml íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì •:**
   ```yaml
   image: ghcr.io/YOUR_USERNAME/spark-custom:latest
   ```

2. **GitHub Token ê¶Œí•œ ì„¤ì •:**
   - GitHub Settings â†’ Developer settings â†’ Personal access tokens
   - `read:packages` ê¶Œí•œì´ ìˆëŠ” í† í° ìƒì„±
   - ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹œ ì‚¬ìš©ìëª…ê³¼ í† í° ì…ë ¥

## ğŸ› ï¸ ê°œë°œ ê°€ì´ë“œ

### ìƒˆë¡œìš´ Spark ì‘ì—… ì¶”ê°€
1. `spark-jobs/` ë””ë ‰í† ë¦¬ì— ìƒˆ YAML íŒŒì¼ ìƒì„±
2. MinIOì— Python/Scala ì½”ë“œ ì—…ë¡œë“œ
3. `kubectl apply -f spark-jobs/your-job.yaml` ì‹¤í–‰

### ë°ì´í„° ì—…ë¡œë“œ (MinIO)
```bash
# MinIO Client ì„¤ì¹˜ í›„
mc alias set local http://localhost:30900 $MINIO_ROOT_USER $MINIO_ROOT_PASSWORD
mc cp your-data.csv local/data-lake/raw/
```

### ì‘ì—… ìƒíƒœ ëª¨ë‹ˆí„°ë§
```bash
# ëª¨ë“  Spark ì‘ì—… í™•ì¸
kubectl get sparkapplications -n spark

# íŠ¹ì • ì‘ì—… ìƒì„¸ ì •ë³´
kubectl describe sparkapplication sample-job -n spark

# Driver Pod ë¡œê·¸ í™•ì¸
kubectl logs -f <driver-pod-name> -n spark

# Spark UI ì ‘ê·¼ (í¬íŠ¸í¬ì›Œë”©)
kubectl port-forward <driver-pod-name> 4040:4040 -n spark
# ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:4040 ì ‘ì†
```

## ğŸ§¹ ì •ë¦¬
```bash
./scripts/cleanup.sh
```

## ğŸ’¡ ì‹¤ë¬´ íŒ

### ë¦¬ì†ŒìŠ¤ ìµœì í™”
- **CPU/Memory ì„¤ì •**: ë°ì´í„° í¬ê¸°ì— ë§ê²Œ driver/executor ë¦¬ì†ŒìŠ¤ ì¡°ì •
- **Executor ê°œìˆ˜**: ë°ì´í„° íŒŒí‹°ì…˜ ìˆ˜ì™€ ë³‘ë ¬ ì²˜ë¦¬ ìˆ˜ì¤€ ê³ ë ¤
- **ë©”ëª¨ë¦¬ ì„¤ì •**: í° ë°ì´í„°ì…‹ì˜ ê²½ìš° executor memory ì¦ê°€

### ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…
- **Spark UI**: ê° ì‘ì—…ì˜ ì‹¤í–‰ ê³„íšê³¼ ì„±ëŠ¥ ë©”íŠ¸ë¦­ í™•ì¸
- **Event Log**: MinIOì˜ spark-logs ë²„í‚·ì—ì„œ ì´ë ¥ í™•ì¸
- **Kubernetes ë¡œê·¸**: kubectl logsë¡œ Pod ìˆ˜ì¤€ ë¡œê·¸ í™•ì¸

### ë°°ì¹˜ ìŠ¤ì¼€ì¤„ë§
```yaml
# CronJobê³¼ ì—°ë™í•˜ì—¬ ì •ê¸° ì‹¤í–‰
apiVersion: batch/v1
kind: CronJob
metadata:
  name: daily-etl
spec:
  schedule: "0 2 * * *"  # ë§¤ì¼ ìƒˆë²½ 2ì‹œ ì‹¤í–‰
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: spark-submit
            image: bitnami/kubectl
            command: ["kubectl", "apply", "-f", "spark-jobs/etl-job.yaml"]
```

## ğŸ“Š ì‚¬ìš© ì‚¬ë¡€

### 1. ETL íŒŒì´í”„ë¼ì¸
```
Raw Data (CSV/JSON) â†’ MinIO â†’ Spark ETL â†’ Processed Data â†’ MinIO
```

### 2. ì‹¤ì‹œê°„ ë¶„ì„
```
Kafka â†’ Spark Streaming â†’ MinIO â†’ Dashboard
```

### 3. ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸
```
Training Data â†’ Spark MLlib â†’ Model â†’ MinIO â†’ Serving
```

### 4. ë°ì´í„° í’ˆì§ˆ ê²€ì¦
```
Data Source â†’ Spark + Great Expectations â†’ Quality Report â†’ MinIO
```

## ğŸ”§ ê³ ê¸‰ ì„¤ì •

### ë„¤íŠ¸ì›Œí¬ ì •ì±… (ë³´ì•ˆ ê°•í™”)
```yaml
# spark namespace ê°„ í†µì‹ ë§Œ í—ˆìš©
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: spark-network-policy
  namespace: spark
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: spark
```

### ë¦¬ì†ŒìŠ¤ ì¿¼í„° (ë¦¬ì†ŒìŠ¤ ì œí•œ)
```yaml
# spark namespaceì˜ ì´ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì œí•œ
apiVersion: v1
kind: ResourceQuota
metadata:
  name: spark-quota
  namespace: spark
spec:
  hard:
    requests.cpu: "10"      # ìµœëŒ€ 10 CPU ì½”ì–´
    requests.memory: 20Gi   # ìµœëŒ€ 20GB ë©”ëª¨ë¦¬
    pods: "50"              # ìµœëŒ€ 50ê°œ Pod
```

## ğŸš¨ ì£¼ì˜ì‚¬í•­

1. **NodePort ë³´ì•ˆ**: í”„ë¡œë•ì…˜ì—ì„œëŠ” LoadBalancerë‚˜ Ingress ì‚¬ìš© ê¶Œì¥
2. **ë°ì´í„° ë°±ì—…**: MinIO ë°ì´í„°ëŠ” ë³„ë„ ë°±ì—… ì „ëµ í•„ìš”
3. **ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§**: í´ëŸ¬ìŠ¤í„° ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì§€ì† ëª¨ë‹ˆí„°ë§
4. **Secret ê´€ë¦¬**: ì‹¤ì œ ìš´ì˜ì‹œ Secretì„ ì½”ë“œì— í•˜ë“œì½”ë”©í•˜ì§€ ë§ê³  ë³„ë„ ê´€ë¦¬

## ğŸ“š ì°¸ê³  ìë£Œ

- [Spark on Kubernetes ê³µì‹ ë¬¸ì„œ](https://spark.apache.org/docs/latest/running-on-kubernetes.html)
- [MinIO Kubernetes ê°€ì´ë“œ](https://min.io/docs/minio/kubernetes/upstream/)
- [Spark Operator GitHub](https://github.com/GoogleCloudPlatform/spark-on-k8s-operator)
