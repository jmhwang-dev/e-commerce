{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd15bc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/23 14:54:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from service.utils.spark import get_spark_session\n",
    "# spark = SparkSession.builder.getOrCreate()\n",
    "spark = get_spark_session(dev=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a8936a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_namespace = 'gold' \n",
    "spark.sql(f\"CREATE NAMESPACE IF NOT EXISTS {test_namespace}\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55e83d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/23 14:55:00 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    }
   ],
   "source": [
    "payment_df = spark.read.csv(\"s3a://warehousedev/bronze/tsv/payment.tsv\", header=True, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fc4fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_customer_id = payment_df.select('order_id', 'customer_id').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "459d6dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_status_df = spark.read.csv(\"s3a://warehousedev/bronze/tsv/order_status.tsv\", header=True, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0180414",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivered_order_id = order_status_df.filter(F.col('status') == 'delivered_customer').select('order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58e32db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivered_order_status = order_status_df.join(delivered_order_id, on='order_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4841c0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "format_string = 'yyyy-MM-dd HH:mm:ss'\n",
    "delivered_order_status = delivered_order_status.withColumn('timestamp_clean', F.substring(F.col('timestamp'), 1, 19)) \\\n",
    "                                .withColumn('timestamp', F.to_timestamp('timestamp_clean', 'yyyy-MM-dd HH:mm:ss')) \\\n",
    "                                .drop('timestamp_clean')\n",
    "delivered_order_status.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae13f068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "distinct_status = delivered_order_status.select('status').distinct().collect()\n",
    "pivot_values = [row.status for row in distinct_status]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "618af900",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_order_status_df = delivered_order_status.groupBy('order_id') \\\n",
    "    .pivot('status', pivot_values) \\\n",
    "    .agg(F.first('timestamp'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8df8dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_order_customer_df = pivoted_order_status_df.join(order_customer_id, on='order_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6116e89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "# stauts가 하나라도 null인 row 확인. 격리 필요\n",
    "conditions = [F.isnull(F.col(c)) for c in pivoted_order_customer_df.columns]\n",
    "final_condition = reduce(lambda a, b: a | b, conditions)\n",
    "rows_with_any_na = pivoted_order_customer_df.filter(final_condition)\n",
    "rows_with_any_na.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f9c27df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_order_timestamp = pivoted_order_customer_df.select('order_id', 'customer_id', 'purchase', 'approved', 'delivered_carrier', 'delivered_customer').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea884fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tmp_order_timestamp.writeTo(f\"{test_namespace}.tmp_order_timestamp\").createOrReplace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "073b76c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- purchase: timestamp (nullable = true)\n",
      " |-- approved: timestamp (nullable = true)\n",
      " |-- delivered_carrier: timestamp (nullable = true)\n",
      " |-- delivered_customer: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp_order_timestamp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1139c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
