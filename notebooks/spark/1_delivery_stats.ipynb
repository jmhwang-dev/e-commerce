{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd15bc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/21 13:18:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from service.utils.spark import get_spark_session\n",
    "spark = get_spark_session(dev=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a8936a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_namespace = 'gold' \n",
    "spark.sql(f\"CREATE NAMESPACE IF NOT EXISTS {test_namespace}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a2cb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "|order_id                        |purchase           |approved           |delivered_carrier  |delivered_customer |\n",
      "+--------------------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "|a9a93c428c6103f2151bb63a1d32a520|2017-01-14 17:57:50|2017-01-17 10:55:13|2017-01-20 17:58:58|2017-01-30 18:37:44|\n",
      "|56ef80c564f6fd57cc662adee0379746|2017-01-16 14:24:22|2017-01-16 14:35:17|2017-01-16 15:21:56|2017-01-23 08:56:05|\n",
      "|f9427374480e37251d5c279ebc41a3ab|2017-01-17 14:57:45|2017-01-18 02:10:16|2017-01-19 09:12:51|2017-01-24 15:14:01|\n",
      "|d6d7c431275f0029dcc3538850930046|2017-01-19 14:28:48|2017-01-19 14:41:56|2017-01-24 10:05:23|2017-01-31 12:26:08|\n",
      "|0957ed870116e596b800540427c61497|2017-01-29 22:14:49|2017-01-29 22:33:34|2017-01-30 08:27:47|2017-02-08 17:14:55|\n",
      "+--------------------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complete_order_timestamp_df = spark.read.table(f\"{test_namespace}.complete_order_timestamp\")\n",
    "complete_order_timestamp_df.show(n=5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26f83b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/21 13:18:28 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+-------------------+-------------------+-----------------------+\n",
      "|            order_id|           purchase|           approved|  delivered_carrier| delivered_customer|estimated_delivery_date|\n",
      "+--------------------+-------------------+-------------------+-------------------+-------------------+-----------------------+\n",
      "|a9a93c428c6103f21...|2017-01-14 17:57:50|2017-01-17 10:55:13|2017-01-20 17:58:58|2017-01-30 18:37:44|    2017-02-28 00:00:00|\n",
      "|56ef80c564f6fd57c...|2017-01-16 14:24:22|2017-01-16 14:35:17|2017-01-16 15:21:56|2017-01-23 08:56:05|    2017-02-24 00:00:00|\n",
      "|f9427374480e37251...|2017-01-17 14:57:45|2017-01-18 02:10:16|2017-01-19 09:12:51|2017-01-24 15:14:01|    2017-02-23 00:00:00|\n",
      "|d6d7c431275f0029d...|2017-01-19 14:28:48|2017-01-19 14:41:56|2017-01-24 10:05:23|2017-01-31 12:26:08|    2017-03-13 00:00:00|\n",
      "|0957ed870116e596b...|2017-01-29 22:14:49|2017-01-29 22:33:34|2017-01-30 08:27:47|2017-02-08 17:14:55|    2017-03-20 00:00:00|\n",
      "|c1cb3668980881dd3...|2017-02-15 20:37:22|2017-02-15 20:45:18|2017-02-16 09:50:13|2017-03-06 08:43:46|    2017-03-24 00:00:00|\n",
      "|55ecd90110224e06d...|2017-02-22 09:19:58|2017-02-22 09:31:32|2017-02-22 10:36:49|2017-03-01 08:27:48|    2017-03-23 00:00:00|\n",
      "|dd129706fb900252b...|2017-02-22 09:47:07|2017-02-23 02:42:32|2017-02-24 09:52:25|2017-03-06 12:38:58|    2017-03-22 00:00:00|\n",
      "|78cd965d0bc0388d3...|2017-02-22 21:56:03|2017-02-22 22:10:07|2017-03-01 10:05:23|2017-03-10 11:14:47|    2017-03-28 00:00:00|\n",
      "|e0af6cabd93711240...|2017-02-23 15:46:42|2017-02-23 15:55:20|2017-02-24 09:47:32|2017-03-03 10:51:53|    2017-03-16 00:00:00|\n",
      "|5000591796ae43a6d...|2017-03-02 14:06:01|2017-03-08 09:15:19|2017-03-10 09:15:17|2017-03-14 11:22:07|    2017-03-21 00:00:00|\n",
      "|5db54d41d5ebd6d76...|2017-03-02 18:53:45|2017-03-03 18:55:23|2017-03-06 11:20:14|2017-03-16 11:09:46|    2017-03-31 00:00:00|\n",
      "|8a6927284335d25c4...|2017-03-03 15:44:38|2017-03-03 15:55:11|2017-03-08 09:57:20|2017-03-13 12:42:27|    2017-03-27 00:00:00|\n",
      "|1801c6babedcb89ce...|2017-03-03 15:48:57|2017-03-04 06:45:13|2017-03-06 14:03:45|2017-03-16 15:12:32|    2017-04-07 00:00:00|\n",
      "|cd05a1fc2781f43f5...|2017-03-08 11:17:14|2017-03-08 11:30:08|2017-03-08 12:03:44|2017-03-14 10:08:01|    2017-03-30 00:00:00|\n",
      "|744dddb0362cbcb14...|2017-03-08 19:30:26|2017-03-08 19:30:26|2017-03-10 10:48:01|2017-03-18 09:21:56|    2017-04-18 00:00:00|\n",
      "|f1d9bf2ed3273bf0d...|2017-03-15 05:11:38|2017-03-15 05:11:38|2017-03-21 13:21:26|2017-03-23 06:43:54|    2017-04-03 00:00:00|\n",
      "|949280c70c6d62ec9...|2017-03-15 09:41:22|2017-03-15 09:41:22|2017-03-16 08:57:18|2017-04-10 12:12:48|    2017-04-10 00:00:00|\n",
      "|fde57015e8a551f04...|2017-03-15 21:55:28|2017-03-15 21:55:28|2017-03-17 09:11:58|2017-03-27 15:19:03|    2017-04-10 00:00:00|\n",
      "|c2abf9bb9aed7fde7...|2017-03-16 13:30:46|2017-03-16 13:30:46|2017-03-17 12:48:47|2017-03-28 14:09:55|    2017-04-20 00:00:00|\n",
      "+--------------------+-------------------+-------------------+-------------------+-------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ed_df = spark.read.csv(\"s3a://warehousedev/bronze/tsv/estimated_delivery_date.tsv\", header=True, sep='\\t')\n",
    "format_string = 'yyyy-MM-dd HH:mm:ss'\n",
    "ed_df = ed_df.withColumn('estimated_delivery_date', F.to_timestamp('estimated_delivery_date', format_string))\n",
    "order_timestamp_with_ed = complete_order_timestamp_df.join(ed_df, on='order_id', how='inner')\n",
    "order_timestamp_with_ed.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d784d64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+----------------------+-----------------------+-------------------+-------+\n",
      "|            order_id|lead_time_approve_days|lead_time_carrier_days|lead_time_customer_days|total_delivery_days|is_late|\n",
      "+--------------------+----------------------+----------------------+-----------------------+-------------------+-------+\n",
      "|a9a93c428c6103f21...|                     3|                     3|                     10|                 16|  false|\n",
      "|56ef80c564f6fd57c...|                     0|                     0|                      7|                  7|  false|\n",
      "|f9427374480e37251...|                     1|                     1|                      5|                  7|  false|\n",
      "|d6d7c431275f0029d...|                     0|                     5|                      7|                 12|  false|\n",
      "|0957ed870116e596b...|                     0|                     1|                      9|                 10|  false|\n",
      "+--------------------+----------------------+----------------------+-----------------------+-------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delivery_stats = order_timestamp_with_ed \\\n",
    "    .withColumn(\n",
    "        'lead_time_approve_days',\n",
    "        F.datediff(F.col('approved'), F.col('purchase'))) \\\n",
    "    .withColumn(\n",
    "        'lead_time_carrier_days',\n",
    "        F.datediff(F.col('delivered_carrier'), F.col('approved'))) \\\n",
    "    .withColumn(\n",
    "        'lead_time_customer_days',\n",
    "        F.datediff(F.col('delivered_customer'), F.col('delivered_carrier'))) \\\n",
    "    .withColumn(\n",
    "        'total_delivery_days',\n",
    "        F.datediff(F.col('delivered_customer'), F.col('purchase'))) \\\n",
    "    .withColumn(\n",
    "        'is_late',\n",
    "        F.when(F.col('delivered_customer') <= F.col('estimated_delivery_date'), False)\n",
    "        .otherwise(True)\n",
    "    )\n",
    "delivery_stats = delivery_stats.select(\n",
    "    'order_id',\n",
    "    'lead_time_approve_days',\n",
    "    'lead_time_carrier_days',\n",
    "    'lead_time_customer_days',\n",
    "    'total_delivery_days',\n",
    "    'is_late'\n",
    ")\n",
    "delivery_stats.show(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "835f0ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "delivery_stats.writeTo(f\"{test_namespace}.delivery_stats\").using('iceberg').createOrReplace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9753c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
