# ==============================================================================
# 1. Iceberg & Catalog 설정
# Spark가 Iceberg를 사용하고, REST 카탈로그를 통해 메타데이터를 관리하도록 설정합니다.
# ==============================================================================
spark.sql.extensions                                    org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
spark.sql.defaultCatalog                                warehousedev
spark.sql.catalogImplementation                         in-memory

spark.sql.catalog.warehousedev                          org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.warehousedev.type                     rest
spark.sql.catalog.warehousedev.uri                      http://rest-catalog:8181
spark.sql.catalog.warehousedev.warehouse                s3://warehousedev
spark.sql.catalog.warehousedev.io-impl                  org.apache.iceberg.aws.s3.S3FileIO


# ==============================================================================
# 2. S3 & Hadoop 설정 (MinIO 접속 정보)
# Spark가 기본 파일 시스템으로 S3a를 사용하고 MinIO에 접속하도록 설정합니다.
# ==============================================================================
spark.hadoop.fs.s3a.endpoint                    http://minio:9000
spark.hadoop.fs.s3a.access.key                  minioadmin
spark.hadoop.fs.s3a.secret.key                  minioadmin
spark.hadoop.fs.s3a.path.style.access           true
spark.hadoop.fs.s3a.connection.ssl.enabled      false
spark.hadoop.fs.s3a.impl                        org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3.impl                         org.apache.hadoop.fs.s3a.S3AFileSystem


# ==============================================================================
# 3. AWS 리전 및 자격증명 설정
# Iceberg의 S3FileIO (AWS SDK v2)와 Hadoop S3a (AWS SDK v1) 모두를 위한 설정입니다.
# ==============================================================================
# --- Iceberg (S3FileIO)를 위한 설정 ---
spark.sql.catalog.warehousedev.s3.region                   us-east-1
spark.sql.catalog.warehousedev.s3.access-key-id            minioadmin
spark.sql.catalog.warehousedev.s3.secret-access-key        minioadmin
spark.sql.catalog.warehousedev.s3.endpoint                 http://minio:9000
spark.sql.catalog.warehousedev.s3.path-style-access        true

# --- Driver를 위한 리전 설정 ---
# Client 모드에서는 Driver의 JVM 속성을 설정하는 것이 유효합니다.
spark.driver.extraJavaOptions      -Daws.region=us-east-1

# --- Executor를 위한 리전 및 자격증명 설정 ---
# Executor는 항상 원격에서 실행되므로 두 설정 모두 유효합니다.
spark.executor.extraJavaOptions    -Daws.region=us-east-1
spark.executorEnv.AWS_REGION       us-east-1
spark.executorEnv.AWS_ACCESS_KEY_ID   minioadmin
spark.executorEnv.AWS_SECRET_ACCESS_KEY minioadmin


# ==============================================================================
# 4. 실행 및 성능 설정
# Spark 잡의 리소스 할당 및 실행 방식을 제어합니다.
# ==============================================================================
spark.driver.memory                2g
spark.driver.maxResultSize         2g
# client 모드에서는 spark-submit을 실행하는 머신의 리소스를 사용하므로 spark.driver.cores는 무시됩니다.

spark.executor.instances           1
spark.executor.cores               1
spark.executor.memory              1g

spark.dynamicAllocation.enabled    true
spark.dynamicAllocation.minExecutors 1
spark.dynamicAllocation.maxExecutors 2

spark.sql.adaptive.enabled         true
spark.sql.streaming.metricsEnabled true
spark.metrics.appStatusSource.enabled true


# ==============================================================================
# 5. (비활성화됨) Spark History Server 설정
# 디버깅 시 Spark UI를 통해 잡의 실행 기록을 보려면 주석을 해제하세요.
# ==============================================================================
# spark.eventLog.enabled           true
# spark.eventLog.dir               file:///opt/spark/logs/
# spark.history.fs.logDirectory    file:///opt/spark/logs/