{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce44599c",
   "metadata": {},
   "source": [
    "# Here's what I did\n",
    "<pre>\n",
    "- Overall EDA of the data:\n",
    "    1. Shapes:                         data_shape.txt\n",
    "    2. Missing count:                  column_missing_count.csv\n",
    "    3. Types:                          column_type.csv\n",
    "    4. Shared columns across data:     columns_shared_across_csvs.json\n",
    "    5. Terminology for columns:        column_description.csv\n",
    "\n",
    "- Result: ./eda/overall/artifact/*\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5483e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edc41c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACT_DIR = r\"../../artifact/eda/pandas\"\n",
    "DOWNLOAD_PATH = r\"../../downloads/olist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9908850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c7754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = os.path.join(DOWNLOAD_PATH, '*')\n",
    "csv_paths = glob.glob(src_path)\n",
    "csv_paths.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d1bc76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_csv_paths = list(map(os.path.abspath, csv_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4751c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_json = {}\n",
    "\n",
    "file_names = []\n",
    "for abs_path in abs_csv_paths:\n",
    "    _path = os.path.splitext(abs_path)[0]\n",
    "    file_name = os.path.split(_path)[1]\n",
    "    file_names.append(file_name)\n",
    "\n",
    "processed_name = [\n",
    "    re.sub(r\"^olist_(.*)_dataset$\", r\"\\1\", name)\n",
    "    for name in file_names\n",
    "]\n",
    "dataset_var = dict(zip(processed_name, abs_csv_paths))\n",
    "with open(os.path.join(ARTIFACT_DIR, 'paths.json'), \"w\") as f:\n",
    "    json.dump(dataset_var, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf990e6",
   "metadata": {},
   "source": [
    "## Shape of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75cfe602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_path = {}\n",
    "for csv_path in csv_paths:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df_by_path[csv_path] = df\n",
    "    \n",
    "save_path = os.path.join(ARTIFACT_DIR, \"data_shape.txt\")\n",
    "with open(save_path, 'w') as f:\n",
    "    for csv_path, df in df_by_path.items():\n",
    "        file_name = os.path.split(csv_path)[-1]\n",
    "        f.write(f\"{file_name:<40} -> {df.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a699757",
   "metadata": {},
   "source": [
    "## Check missing count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ac802ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = pd.DataFrame(columns=['file_name', 'column_name', 'missing_count'])\n",
    "for csv_path, df in df_by_path.items():\n",
    "    check_missing_ds = df.isna().sum()\n",
    "    tmp_df = check_missing_ds.to_frame(name='missing_count')\n",
    "    tmp_df.index.name = 'column_name'\n",
    "    tmp_df = tmp_df.reset_index()\n",
    "    tmp_df['file_name'] = os.path.split(csv_path)[-1]\n",
    "    missing_df = pd.concat([missing_df, tmp_df])\n",
    "    save_path = os.path.join(ARTIFACT_DIR, \"column_missing_count.csv\")\n",
    "    missing_df.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6f9b5d",
   "metadata": {},
   "source": [
    "## All type of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9489d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_df = pd.DataFrame(columns=['file_name', 'column_name', 'type'])\n",
    "for csv_path, df in df_by_path.items():\n",
    "    type_ds = df.dtypes\n",
    "    tmp_df = type_ds.to_frame(name='type')\n",
    "    tmp_df.index.name = 'column_name'\n",
    "    tmp_df = tmp_df.reset_index()\n",
    "    tmp_df['file_name'] = os.path.split(csv_path)[-1]\n",
    "    type_df = pd.concat([type_df, tmp_df])\n",
    "    save_path = os.path.join(ARTIFACT_DIR, \"column_type.csv\")\n",
    "\n",
    "    type_df.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6846e6f3",
   "metadata": {},
   "source": [
    "## Columns shared across data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9162c2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_by_csv = {}\n",
    "for csv_path, df in df_by_path.items():\n",
    "    columns = sorted(df.columns.to_list())\n",
    "    columns_by_csv[csv_path] = columns\n",
    "\n",
    "# print(json.dumps(columns_by_csv, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1ddc303",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unique_columns = []\n",
    "for columns in list(columns_by_csv.values()):\n",
    "    all_unique_columns += columns\n",
    "all_unique_columns = sorted(set(all_unique_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcd6270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_by_csvs = {}\n",
    "for unique_col in all_unique_columns:\n",
    "    column_by_csvs[unique_col] = []\n",
    "\n",
    "for csv_path, cols in columns_by_csv.items():\n",
    "    for unique_col in column_by_csvs.keys():\n",
    "        if unique_col in cols:\n",
    "            file_name = os.path.split(csv_path)[-1]\n",
    "            column_by_csvs[unique_col].append(file_name)\n",
    "            \n",
    "columns_shared_across_csvs = dict(filter(lambda item: len(item[1]) > 1, column_by_csvs.items()))\n",
    "save_path = os.path.join(ARTIFACT_DIR, \"columns_shared_across_csvs.json\")\n",
    "with open(save_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(columns_shared_across_csvs, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fa4cc4",
   "metadata": {},
   "source": [
    "## Column description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d5f7522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: '../../artifact/eda/pandas/column_description.csv'\n"
     ]
    }
   ],
   "source": [
    "def generate_column_description(description_data, output_file):    \n",
    "    description_list = []\n",
    "    for line in description_data.strip().split('\\n')[1:]:\n",
    "        file_name, column_name, description = line.split(',', 2)\n",
    "        description_list.append([file_name, column_name, description])\n",
    "\n",
    "    df_description = pd.DataFrame(description_list, columns=['file_name', 'column_name', 'description'])\n",
    "    df_description.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    print(f\"Done: '{output_file}'\")\n",
    "\n",
    "\n",
    "description_data = \\\n",
    "\"\"\"file_name,column_name,description\n",
    "olist_customers_dataset.csv,customer_id,고객을 식별하기 위한 고유 ID\n",
    "olist_customers_dataset.csv,customer_unique_id,고객의 고유 식별자(중복되지 않는 ID)\n",
    "olist_customers_dataset.csv,customer_zip_code_prefix,고객의 우편번호 접두사\n",
    "olist_customers_dataset.csv,customer_city,고객이 거주하는 도시\n",
    "olist_customers_dataset.csv,customer_state,고객이 거주하는 주(state)\n",
    "olist_geolocation_dataset.csv,geolocation_zip_code_prefix,위치 정보에 해당하는 우편번호 접두사\n",
    "olist_geolocation_dataset.csv,geolocation_lat,위도(latitude)\n",
    "olist_geolocation_dataset.csv,geolocation_lng,경도(longitude)\n",
    "olist_geolocation_dataset.csv,geolocation_city,위치 정보에 해당하는 도시\n",
    "olist_geolocation_dataset.csv,geolocation_state,위치 정보에 해당하는 주(state)\n",
    "olist_order_items_dataset.csv,order_id,주문을 식별하기 위한 고유 ID\n",
    "olist_order_items_dataset.csv,order_item_id, 해당 주문 내에서 각 상품 아이템을 구분하는 번호\n",
    "olist_order_items_dataset.csv,product_id,상품을 식별하기 위한 고유 ID\n",
    "olist_order_items_dataset.csv,seller_id,판매자를 식별하기 위한 고유 ID\n",
    "olist_order_items_dataset.csv,shipping_limit_date,판매자가 상품을 배송사에 전달해야 하는 기한\n",
    "olist_order_items_dataset.csv,price,상품 가격\n",
    "olist_order_items_dataset.csv,freight_value,배송비(운송 비용)\n",
    "olist_order_payments_dataset.csv,order_id,주문을 식별하기 위한 고유 ID\n",
    "olist_order_payments_dataset.csv,payment_sequential,결제 순서(결제와 관련된 순차적 번호)\n",
    "olist_order_payments_dataset.csv,payment_type,결제 유형(예: credit_card, boleto 등)\n",
    "olist_order_payments_dataset.csv,payment_installments,할부 횟수\n",
    "olist_order_payments_dataset.csv,payment_value,결제 금액\n",
    "olist_order_reviews_dataset.csv,review_id,리뷰를 식별하기 위한 고유 ID\n",
    "olist_order_reviews_dataset.csv,order_id,주문을 식별하기 위한 고유 ID\n",
    "olist_order_reviews_dataset.csv,review_score,리뷰 점수(예: 1~5점)\n",
    "olist_order_reviews_dataset.csv,review_comment_title,리뷰 제목\n",
    "olist_order_reviews_dataset.csv,review_comment_message,리뷰 코멘트 내용\n",
    "olist_order_reviews_dataset.csv,review_creation_date,리뷰가 작성된 날짜\n",
    "olist_order_reviews_dataset.csv,review_answer_timestamp,리뷰에 대한 답변이 작성된 날짜 및 시간\n",
    "olist_orders_dataset.csv,order_id,주문을 식별하기 위한 고유 ID\n",
    "olist_orders_dataset.csv,customer_id,고객을 식별하기 위한 고유 ID\n",
    "olist_orders_dataset.csv,order_status,주문 상태(예: delivered, shipped, canceled 등)\n",
    "olist_orders_dataset.csv,order_purchase_timestamp,주문이 생성된 날짜 및 시간\n",
    "olist_orders_dataset.csv,order_approved_at,주문이 승인된 날짜 및 시간\n",
    "olist_orders_dataset.csv,order_delivered_carrier_date,주문이 배송사에 전달된 날짜\n",
    "olist_orders_dataset.csv,order_delivered_customer_date,주문이 고객에게 배송 완료된 날짜\n",
    "olist_orders_dataset.csv,order_estimated_delivery_date,주문의 예상 배송 날짜\n",
    "olist_products_dataset.csv,product_id,상품을 식별하기 위한 고유 ID\n",
    "olist_products_dataset.csv,product_category_name,상품 카테고리 이름(원어)\n",
    "olist_products_dataset.csv,product_name_lenght,상품 이름의 길이(문자 수)\n",
    "olist_products_dataset.csv,product_description_lenght,상품 설명의 길이(문자 수)\n",
    "olist_products_dataset.csv,product_photos_qty,상품 사진 개수\n",
    "olist_products_dataset.csv,product_weight_g,상품 무게(g)\n",
    "olist_products_dataset.csv,product_length_cm,상품 길이(cm)\n",
    "olist_products_dataset.csv,product_height_cm,상품 높이(cm)\n",
    "olist_products_dataset.csv,product_width_cm,상품 너비(cm)\n",
    "olist_sellers_dataset.csv,seller_id,판매자를 식별하기 위한 고유 ID\n",
    "olist_sellers_dataset.csv,seller_zip_code_prefix,판매자의 우편번호 접두사\n",
    "olist_sellers_dataset.csv,seller_city,판매자가 위치한 도시\n",
    "olist_sellers_dataset.csv,seller_state,판매자가 위치한 주(state)\n",
    "product_category_name_translation.csv,product_category_name,상품 카테고리 이름(원어)\n",
    "product_category_name_translation.csv,product_category_name_english,상품 카테고리 이름(영어)\n",
    "\"\"\"\n",
    "\n",
    "output_file = os.path.join(ARTIFACT_DIR, \"column_description.csv\")\n",
    "generate_column_description(description_data, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e-commerce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
