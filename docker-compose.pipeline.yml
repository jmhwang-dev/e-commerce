x-spark-common: &spark-common
  build:
    context: ./infra/spark
    dockerfile: Dockerfile
  image: ecommerce-spark:latest

services:
  spark-client:
    <<: *spark-common
    hostname: spark-client
    container_name: spark-client
    network_mode: host
    depends_on:
      - spark-master
      # - spark-worker
      - spark-history
    # ports:
    #   - "4040:4040"   # application web ui
    #   - "19080:9080"  # jmx exporter of driver for subscriber bronze to publish silver
    #   - "19081:9081"  # jmx exporter of driver for subscriber bronze to load bronze
    #   - "19082:9082"

    volumes:
      - ./configs/spark:/opt/spark/conf
      - ./configs/kafka:/configs/kafka:ro
      - ./notebooks/spark:/opt/spark/work-dir
      - ./jobs/:/jobs/
      - ./src/:/mnt/src
      - ./logs/spark/:/opt/spark/logs/
      - ./downloads/jmx_exporter:/mnt/jmx_exporter/
      - ./configs/jmx/spark_driver.yml:/mnt/configs/jmx/spark_driver.yml

    working_dir: /
    environment:
      - SPARK_NO_DAEMONIZE=true  # run foreground
      - PYTHONPATH=/mnt/src
      - spark.driver.bindAddress=0.0.0.0
      - SPARK_LOCAL_HOSTNAME=192.168.45.191   # Spark가 호스트네임 대신 IP 사용

    mem_limit: 3g  # Docker 컨테이너 메모리 제한. JVM 힙메모리는 이것보다 작아야함.
    cpus: 1.0  # 드라이버 코어 제한

    extra_hosts:
      - "spark-client:127.0.0.1"
 
    command: tail -f /dev/null

  spark-worker:
    <<: *spark-common
    container_name: spark-worker
    ports:
      - "8084:8081"   # web ui
      - "19083:9080"  # jmx exporter executor for subscriber bronze to publish silver
      - "19084:9081"  # jmx exporter executor for subscriber bronze to load bronze
      - "19085:9082"

    environment:
      SPARK_WORKER_MEMORY: 16g  # upper limit of memory to use
      SPARK_WORKER_CORES: 14    # upper limit of cores to use
    volumes:
      - ./configs/spark:/opt/spark/conf
      - ./downloads/jmx_exporter:/mnt/jmx_exporter/
      - ./configs/jmx/spark_executor.yml:/mnt/configs/jmx/spark_executor.yml

    command: >
      bash -c "
        sleep 10 &&
        /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
      "

  spark-master:
      <<: *spark-common
      hostname: spark-master
      container_name: spark-master
      depends_on:
        - spark-history
      ports:
        - "18081:8080"  # web ui: 클러스터 상태 모니터링
        - "7077:7077"   # Spark 클러스터 통신: 클러스터 매니저 <-> 워커노드
      volumes:
        - ./configs/spark:/opt/spark/conf
      command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    
  spark-history:
    <<: *spark-common
    container_name: spark-history
    ports:
      - "18080:18080"
    # environment:
    #   - SPARK_NO_DAEMONIZE=true
    # command: >
    #   /bin/bash -c "
    #     /opt/spark/sbin/start-history-server.sh
    #   "
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer
    volumes:
      - ./configs/spark:/opt/spark/conf
      - ./logs/spark/:/opt/spark/logs/

  init-spark:
    <<: *spark-common
    container_name: init-spark
    depends_on:
      - spark-master
    volumes:
      - ./configs/spark:/opt/spark/conf
    entrypoint: >
      bash -c "
        echo 'Waiting for master/catalog…';
        sleep 10;
        spark-sql -e \"CREATE NAMESPACE IF NOT EXISTS warehousedev.default;\"
      "

  # # Dynamic Allocation 쓸 때 필수
  # spark-shuffle-service:
  #   <<: *spark-common
  #   container_name: spark-shuffle
  #   network_mode: host
  #   restart: unless-stopped
  #   volumes:
  #     - ./configs/spark:/opt/spark/conf:ro
  #   entrypoint: []
  #   command: /opt/spark/bin/spark-class org.apache.spark.deploy.ExternalShuffleService

  # dbt:
  #   container_name: dbt
  #   image: ghcr.io/dbt-labs/dbt-spark:1.9.0
  #   depends_on:
  #     - spark-client
  #   volumes: 
  #     - ./infra/dbt:/usr/app/dbt
  #     - ./configs/dbt/profiles.yml:/root/.dbt/profiles.yml
  #   entrypoint: ["tail", "-f", "/dev/null"]