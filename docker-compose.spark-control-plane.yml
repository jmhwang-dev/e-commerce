# -------------------------------------------------------
# [1] 공통 설정 (이미지와 네트워크만 관리)
# -------------------------------------------------------
x-spark-common: &spark-common
  image: ghcr.io/jmhwang-dev/warehouse:sp3.5.6-ice1.9.1
  # [핵심] 리눅스 머신이므로 Host 모드 사용 (성능 및 포트 이슈 해결)
  network_mode: host

services:
  # -------------------------------------------------------
  # 1. Spark Client (Driver 역할)
  # -------------------------------------------------------
  spark-client:
    <<: *spark-common
    container_name: spark-client
    environment:
      PYTHONPATH: "/mnt/src"
      SPARK_DRIVER_HOST: 192.168.45.192
      SPARK_DRIVER_BIND_ADDRESS: 0.0.0.0
      
    mem_limit: 3g
    cpus: 1.0

    command: tail -f /dev/null
    volumes:
      - ./configs/spark:/opt/spark/conf
      - ./configs/kafka:/configs/kafka:ro
      - ./notebooks/spark:/opt/spark/work-dir
      - ./jobs/:/jobs/
      - ./src/:/mnt/src
      - ./logs/spark/:/opt/spark/logs/
      
      # JMX 모니터링
      - ./infra/shared:/mnt/shared/
      - ./configs/jmx/spark_driver.yml:/mnt/configs/jmx/spark_driver.yml

    working_dir: /

  # -------------------------------------------------------
  # 2. CDC Master (Port: 7077, 8080)
  # -------------------------------------------------------
  spark-master-cdc:
    <<: *spark-common
    container_name: spark-master-cdc
    environment:
      SPARK_NO_DAEMONIZE: "true"
      
      # [핵심] 마스터가 사용할 물리 IP 및 포트 지정
      SPARK_MASTER_HOST: 192.168.45.192
      SPARK_MASTER_PORT: 7077
      SPARK_MASTER_WEBUI_PORT: 8080
      SPARK_MASTER_BIND_ADDRESS: 0.0.0.0
      
    volumes:
      - ./configs/spark:/opt/spark/conf
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    depends_on:
      - spark-history

  # -------------------------------------------------------
  # 3. ETL Master (Port: 7078, 8081 - 포트 충돌 방지)
  # -------------------------------------------------------
  spark-master-etl:
    <<: *spark-common
    container_name: spark-master-etl
    environment:
      SPARK_NO_DAEMONIZE: "true"
      
      # [핵심] 마스터가 사용할 물리 IP 및 변경된 포트 지정
      SPARK_MASTER_HOST: 192.168.45.192
      SPARK_MASTER_PORT: 7078
      SPARK_MASTER_WEBUI_PORT: 8081
      SPARK_MASTER_BIND_ADDRESS: 0.0.0.0
      
    volumes:
      - ./configs/spark:/opt/spark/conf
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    depends_on:
      - spark-history

  # -------------------------------------------------------
  # 4. History Server (Port: 18080)
  # -------------------------------------------------------
  spark-history:
    <<: *spark-common
    container_name: spark-history
    restart: unless-stopped
    environment:
      SPARK_NO_DAEMONIZE: "true"
      SPARK_HISTORY_OPTS: "-Dspark.history.ui.port=18080"
      
    volumes:
      - ./configs/spark:/opt/spark/conf
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer

  # -------------------------------------------------------
  # 5. Init Job (Iceberg Namespace 생성)
  # -------------------------------------------------------
  init-spark:
    <<: *spark-common
    container_name: init-spark
    depends_on:
      - spark-master-cdc
      - spark-master-etl
    volumes:
      - ./configs/spark:/opt/spark/conf
    # Host 모드이므로 Desktop(192.168.45.191)의 MinIO에 바로 접근 가능
    entrypoint: >
      bash -c "
        echo 'Waiting for cluster stability...';
        sleep 10;
        echo 'Initializing Iceberg Namespace via S3 (MinIO)...';
        /opt/spark/bin/spark-sql \
        --master local[*] \
        -e \"CREATE NAMESPACE IF NOT EXISTS warehousedev.default;\"
      "