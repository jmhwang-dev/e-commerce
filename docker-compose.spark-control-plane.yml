# -------------------------------------------------------
# [1] 공통 설정 (이미지와 네트워크만 관리)
# -------------------------------------------------------
x-spark-common: &spark-common
  image: ghcr.io/jmhwang-dev/warehouse:sp3.5.6-ice1.9.1
  # [변경] macOS Docker Desktop의 VM 격리 특성으로 host 모드 미지원.
  # Bridge 모드(기본값) 사용 및 명시적 포트 매핑(Ports Mapping) 적용.
  # network_mode: host 

services:
  # -------------------------------------------------------
  # 1. Spark Client (Driver 역할)
  # -------------------------------------------------------
  spark-client:
    <<: *spark-common
    container_name: spark-client
    
    # Bridge 모드 사용에 따른 외부(워커) 접속용 포트 개방
    ports:
      # [CDC용]
      - "7003:7003" # Driver
      - "7004:7004" # BlockManager
      
      # [Stream용]
      - "7005:7005" # Driver
      - "7006:7006" # BlockManager
      
      - "4040:4040" # CDC UI
      - "4041:4041" # Stream UI (UI 포트도 겹치면 안 됨)
      
    environment:
      PYTHONPATH: "/mnt/src"
      
    mem_limit: 5g
    cpus: 3.0

    command: tail -f /dev/null
    volumes:
      - ./configs/spark:/opt/spark/conf
      - ./configs/kafka:/configs/kafka:ro
      - ./notebooks/spark:/opt/spark/work-dir
      - ./jobs/:/jobs/
      - ./src/:/mnt/src
      - ./logs/spark/:/opt/spark/logs/
      - ./infra/shared:/mnt/shared/
      - ./configs/jmx/spark_driver.yml:/mnt/configs/jmx/spark_driver.yml

    working_dir: /

  # -------------------------------------------------------
  # 2. CDC Master (Port: 7077, 8080)
  # -------------------------------------------------------
  spark-master-cdc:
    <<: *spark-common
    container_name: spark-master-cdc
    
    # Bridge 모드 사용에 따른 외부(워커) 접속용 포트 개방
    ports:
      - "7077:7077"
      - "8080:8080"

    environment:
      SPARK_NO_DAEMONIZE: "true"
      SPARK_MASTER_HOST: 0.0.0.0
      SPARK_PUBLIC_DNS: 192.168.45.190
      SPARK_MASTER_PORT: 7077
      SPARK_MASTER_WEBUI_PORT: 8080
      
    volumes:
      - ./configs/spark:/opt/spark/conf
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    depends_on:
      - spark-history

  # -------------------------------------------------------
  # 3. ETL Master (Stream) (Port: 7078, 8081)
  # -------------------------------------------------------
  spark-master-stream:
    <<: *spark-common
    container_name: spark-master-stream
    
    # Bridge 모드 사용에 따른 외부(워커) 접속용 포트 개방
    ports:
      - "7078:7078"
      - "8081:8081"

    environment:
      SPARK_NO_DAEMONIZE: "true"
      SPARK_MASTER_HOST: 0.0.0.0
      SPARK_PUBLIC_DNS: 192.168.45.190
      SPARK_MASTER_PORT: 7078
      SPARK_MASTER_WEBUI_PORT: 8081
      
    volumes:
      - ./configs/spark:/opt/spark/conf
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    depends_on:
      - spark-history

  # -------------------------------------------------------
  # 4. Batch Master (Port: 7079, 8083)
  # -------------------------------------------------------
  spark-master-batch:
    <<: *spark-common
    container_name: spark-master-batch
    
    ports:
      - "7079:7079"
      - "8083:8083"

    environment:
      SPARK_NO_DAEMONIZE: "true"
      SPARK_MASTER_HOST: 0.0.0.0
      SPARK_PUBLIC_DNS: 192.168.45.190
      SPARK_MASTER_PORT: 7079
      SPARK_MASTER_WEBUI_PORT: 8083
      
    volumes:
      - ./configs/spark:/opt/spark/conf
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    depends_on:
      - spark-history

  # -------------------------------------------------------
  # 5. History Server (Port: 18080)
  # -------------------------------------------------------
  spark-history:
    <<: *spark-common
    container_name: spark-history
    restart: unless-stopped
    
    ports:
      - "18080:18080"

    environment:
      SPARK_NO_DAEMONIZE: "true"
      SPARK_HISTORY_OPTS: "-Dspark.history.ui.port=18080"
      # 워커와 직접 통신하지 않으므로 Public DNS 불필요. S3(MinIO) 연결 설정 중요.
      
    volumes:
      - ./configs/spark:/opt/spark/conf
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer

  # -------------------------------------------------------
  # 6. Init Job (Iceberg Namespace 생성)
  # -------------------------------------------------------
  init-spark:
    <<: *spark-common
    container_name: init-spark
    depends_on:
      - spark-master-cdc
      - spark-master-batch
      - spark-master-stream
    volumes:
      - ./configs/spark:/opt/spark/conf
    # Bridge 모드이나 Desktop(192.168.45.191)은 외부망이므로 접근 가능.
    entrypoint: >
      bash -c "
        echo 'Waiting for cluster stability...';
        sleep 10;
        echo 'Initializing Iceberg Namespace via S3 (MinIO)...';
        /opt/spark/bin/spark-sql \
        --master local[*] \
        -e \"CREATE NAMESPACE IF NOT EXISTS warehousedev.default;\"
      "